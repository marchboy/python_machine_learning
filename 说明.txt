基于迁移学习和双向LSTM的核心实体识别

==============================================================
总的步骤（在train_and_predict.py中一一对应）
==============================================================

1、训练语料和测试语料都分词，目前用的是结巴分词；
2、转化为5tag标注问题，构建训练标签；
3、训练语料和测试语料一起训练Word2Vec模型；
4、用双层双向LSTM训练标注模型，基于seq2seq的思想；
5、用模型进行预测，预测准确率大约会在0.46～0.52波动；
6、将预测结果当作标签数据，与训练数据一起，重新训练模型；
7、用新模型预测，预测准确率会在0.5～0.55波动；
8、比较两次预测结果，取交集当做标签数据，与训练数据一起，重新训练模型；
9、用新模型预测，预测准确率基本保持在0.53～0.56。

==============================================================
编译环境：
==============================================================

硬件环境：
1、96G内存（事实上用到10G左右）
2、GTX960显卡（GPU加速训练）

软件环境：
1、CentOS 7
2、Python 2.7（以下均为Python第三方库）
3、结巴分词
4、Numpy
5、SciPy
6、Pandas
7、Keras（官方GitHub版本）
8、Gensim
9、H5PY
10、tqdm

==============================================================
文件使用说明：
==============================================================

train_and_predict.py

包含了从训练到预测的整个过程，只要“未开放的验证数据”格式跟“开放的测试数据”opendata_20w格式一样，那么就可以
与train_and_predict.py放在同一目录，然后运行
python train_and_predict.py
就可以完成整个过程，并且会生成一系列文件：

--------------------------------------------------------------
word2vec_words_final.model，word2vec模型

words_seq2seq_final_1.model，首次得到的双层双向LSTM模型
--- result1.txt，首次预测结果文件
--- result1.zip，首次预测结果文件压缩包

words_seq2seq_final_2.model，通过第一次迁移学习后得到的模型
--- result2.txt，再次预测结果文件
--- result2.zip，再次预测结果文件压缩包

words_seq2seq_final_3.model，通过第二次迁移学习后得到的模型
--- result3.txt，再次预测结果文件
--- result3.zip，再次预测结果文件压缩包

words_seq2seq_final_4.model，通过第三次迁移学习后得到的模型
--- result4.txt，再次预测结果文件
--- result4.zip，再次预测结果文件压缩包

words_seq2seq_final_5.model，通过第四次迁移学习后得到的模型
--- result5.txt，再次预测结果文件
--- result5.zip，再次预测结果文件压缩包
---------------------------------------------------------------

==============================================================
思路说明：
==============================================================

迁移学习体现在：
1、用训练语料和测试语料一起训练Word2Vec，使得词向量本捕捉了测试语料的语义；
2、用训练语料训练模型；
3、得到模型后，对测试语料预测，把预测结果跟训练语料一起训练新的模型；
4、用新的模型预测，模型效果会有一定提升；
5、对比两次预测结果，如果两次预测结果都一样，那说明这个预测结果很有可能是对的，用这部分“很有可能是对的”的测试结果来训练模型；
6、用更新的模型预测；
7、如果你愿意，可以继续重复第4、5、6步。

双向LSTM的思路：
1、分词；
2、转换为5tag标注问题（0:非核心实体，1:单词的核心实体，2:多词核心实体的首词，3:多词核心实体的中间部分，4:多词核心实体的末词）；
3、通过双向LSTM，直接对输入句子输出预测标注序列；
4、通过viterbi算法来获得标注结果；
5、因为常规的LSTM存在后面的词比前面的词更重要的弊端，因此用双向LSTM。