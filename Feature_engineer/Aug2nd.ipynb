{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "\"\"\"\n",
    "Some global parameters to be tuned here.\n",
    "\"\"\"\n",
    "date_range = (\"2016-01-01T00:00:00\", \"2016-03-31T23:59:59\")\n",
    "\n",
    "time_start = int(time.mktime(time.strptime(date_range[0], '%Y-%m-%dT%H:%M:%S')))\n",
    "time_end = int(time.mktime(time.strptime(date_range[1], '%Y-%m-%dT%H:%M:%S')))\n",
    "\n",
    "# TODO: def foo()\n",
    "# 7 days as a period\n",
    "period = 604800.0\n",
    "n_period = int(math.ceil((time_end - time_start)/(period)))\n",
    "\n",
    "\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open( name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open( name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def time_str2int(in_time):\n",
    "    return int(time.mktime(time.strptime(in_time, '%Y-%m-%d %H:%M:%S'))) \n",
    "\n",
    "def string2list(in_str):\n",
    "    ret = in_str.split('],[')\n",
    "    temp = []\n",
    "    for each in ret:\n",
    "        temp.append(each.strip('[').strip(']').split(','))\n",
    "    return temp\n",
    "    #return pd.DataFrame(temp)\n",
    "\n",
    "\n",
    "def get_eventids(filename):\n",
    "    # Get logs within the time range\n",
    "    t = pd.read_csv(filename, sep='\\t', header = None)\n",
    "    t1 = t[t[2] >= time_start]\n",
    "    data_all = t1[t1[2] <= time_end]\n",
    "\n",
    "    grouped_by_eventid = data_all.groupby([1])\n",
    "    eventids = grouped_by_eventid.groups.keys()\n",
    "    return eventids\n",
    "\n",
    "\n",
    "def get_uid2uuid(userbase_dataframe, uuid_list):\n",
    "    u_by_uuid = userbase_dataframe[userbase_dataframe[1].isin(set(uuid_list))]\n",
    "    u_by_uuid = u_by_uuid[u_by_uuid[1]!= 'cfcd208495d565ef66e7dff9f98764da']\n",
    "    uid2uuid = {}\n",
    "    for each in u_by_uuid.iterrows():\n",
    "        if each[1][0] not in uid2uuid:\n",
    "            uid2uuid[each[1][0]] = []\n",
    "        uid2uuid[each[1][0]].append(each[1][1])\n",
    "    return uid2uuid\n",
    "\n",
    "def feature_expenditure(filename, userbase_dataframe, uuid_list):\n",
    "\n",
    "    uid2uuid = get_uid2uuid(userbase_dataframe, uuid_list)\n",
    "    for each in uid2uuid:\n",
    "        if len(uid2uuid[each]) > 1:\n",
    "            print \"Found one-to-many uid to uuid relationship, but I ignored it for simplicity.\"\n",
    "\n",
    "    e = pd.read_csv(filename, sep='\\t', header = None)\n",
    "    exp = e[e[0].isin(set(uid2uuid.keys()))]\n",
    "    exp[-1] = exp[0].map(lambda x: uid2uuid[x][0])\n",
    "    exp_by_uuid = exp.groupby([-1])\n",
    "\n",
    "    expenditure_dict = {}\n",
    "    for each in exp_by_uuid.groups:\n",
    "        index_list = exp_by_uuid.groups[each]\n",
    "        data_frame = exp.loc[index_list]\n",
    "        \n",
    "        reg = []\n",
    "        rec = []\n",
    "        pay = []\n",
    "        for row in data_frame.iterrows():\n",
    "            reg += string2list(row[1][1])\n",
    "            rec += string2list(row[1][2])\n",
    "            pay += string2list(row[1][3])\n",
    "        reg = pd.DataFrame(reg)\n",
    "        rec = pd.DataFrame(rec)\n",
    "        pay = pd.DataFrame(pay)\n",
    "        \n",
    "        \n",
    "        \"\"\"reg\"\"\"\n",
    "        reg = reg[reg[3]!='0']\n",
    "        try: # no reg means no rec or pay\n",
    "            #[0] #uid\n",
    "            temp = [len(index_list)]\n",
    "            #[1] #games\n",
    "            temp.append(len(reg[0]))\n",
    "            #[2] # unique games\n",
    "            temp.append(len(reg[1].unique()))\n",
    "            #[3] # unique cid\n",
    "            temp.append(len(reg[2].unique()))\n",
    "            #[4] # unique game_uid\n",
    "            temp.append(len(reg[4].unique()))\n",
    "            #[5] # unique ucid\n",
    "            temp.append(len(reg[5].unique()))\n",
    "\n",
    "            reg_time = reg[3].map(time_str2int)\n",
    "            #[6] max reg time\n",
    "            temp.append(max(reg_time))\n",
    "            #[7] min reg time\n",
    "            temp.append(min(reg_time))\n",
    "            #[8] reg time span\n",
    "            temp.append(max(reg_time) - min(reg_time))\n",
    "            #[9] reg time mean\n",
    "            temp.append(reg_time.mean())\n",
    "            #[10] reg time mid\n",
    "            temp.append(reg_time.quantile(0.5))\n",
    "            #[11] reg time std\n",
    "            temp.append(np.std(reg_time))\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        \"\"\"rec\"\"\"\n",
    "        rec = rec[rec[2]!='0']\n",
    "        if len(rec) == 0:\n",
    "            temp += [np.nan] * 12\n",
    "        else:\n",
    "            #[12] # rec\n",
    "            temp.append(len(rec[0]))\n",
    "            #[13] # unique games\n",
    "            temp.append(len(rec[0].unique()))\n",
    "            #[14] # unique types\n",
    "            temp.append(len(rec[1].unique()))\n",
    "            #[15] # unique cid\n",
    "            temp.append(len(rec[3].unique()))\n",
    "            #[16] # unique item\n",
    "            temp.append(len(rec[4].unique()))    \n",
    "            #[17] # unique appid\n",
    "            temp.append(len(rec[5].unique()))  \n",
    "            #[18] # unique pay_from\n",
    "            temp.append(len(rec[6].unique()))  \n",
    "\n",
    "            rec_time = rec[2].map(time_str2int)\n",
    "            #[19] max reg time\n",
    "            temp.append(max(rec_time))\n",
    "            #[20] min reg time\n",
    "            temp.append(min(rec_time))\n",
    "            #[21] reg time span\n",
    "            temp.append(max(rec_time) - min(rec_time))\n",
    "            #[21] reg time mean\n",
    "            temp.append(rec_time.mean())\n",
    "            #[22] reg time mid\n",
    "            temp.append(rec_time.quantile(0.5))\n",
    "            #[23] reg time std\n",
    "            temp.append(np.std(rec_time))\n",
    "        \n",
    "        pay = pay[pay[2]!='0']\n",
    "        if len(pay) == 0:\n",
    "            temp += [np.nan] * 11\n",
    "        else:\n",
    "            #[24] # payments\n",
    "            temp.append(len(pay[0]))\n",
    "            #[25] # unique games\n",
    "            temp.append(len(pay[0].unique()))\n",
    "            #[26] # unique cid\n",
    "            temp.append(len(pay[1].unique()))\n",
    "            #[27] # unique appid\n",
    "            temp.append(len(pay[3].unique()))\n",
    "            #[28] # unique item\n",
    "            temp.append(len(pay[4].unique()))    \n",
    "            #[29] # unique porder\n",
    "            temp.append(len(pay[5].unique()))  \n",
    "\n",
    "\n",
    "            pay_time = pay[2].map(time_str2int)\n",
    "            #[30] max reg time\n",
    "            temp.append(max(pay_time))\n",
    "            #[31] min reg time\n",
    "            temp.append(min(pay_time))\n",
    "            #[32] reg time span\n",
    "            temp.append(max(pay_time) - min(pay_time))\n",
    "            #[33] reg time mean\n",
    "            temp.append(pay_time.mean(0.5))\n",
    "            #[34] reg time mid\n",
    "            temp.append(pay_time.quantile(0.5))\n",
    "            #[33] reg time std\n",
    "            temp.append(np.std(pay_time))\n",
    "        \n",
    "        expenditure_dict[each] = temp\n",
    "\n",
    "    return expenditure_dict  \n",
    "\n",
    "\n",
    "def cleaning_filter(input_element, filter_list, replacement):\n",
    "    if input_element not in filter_list:\n",
    "        return replacement\n",
    "    return input_element\n",
    "\n",
    "def ucid_cleaner(input_element):\n",
    "    try:\n",
    "        ret = eval(input_element)\n",
    "    except:\n",
    "        ret = []\n",
    "    if type(ret) is list:\n",
    "        return ret\n",
    "    elif type(ret) is dict:\n",
    "        return map(lambda x: int(x), ret.values())\n",
    "    elif type(ret) is int:\n",
    "        return [ret]\n",
    "    else:\n",
    "        print \"Error in ucid_cleaner\"\n",
    "\n",
    "def feature_userbase(userbase_dataframe, uuid_list):\n",
    "    \"\"\"\n",
    "    Input: userbase_dataframe-- stacked userbases by pandas.read_csv()\n",
    "           uuid_list-- -- uuids to be extracted from userbase\n",
    "\n",
    "    Output: a dictionary of (uuid, feature) pairs\n",
    "    \"\"\"\n",
    "\n",
    "    u_by_uuid = userbase_dataframe[userbase_dataframe[1].isin(set(uuid_list))]\n",
    "    # remove empty uuids: 'cfcd208495d565ef66e7dff9f98764da' \n",
    "    u_by_uuid = u_by_uuid[u_by_uuid[1] != 'cfcd208495d565ef66e7dff9f98764da']\n",
    "    # remove NaNs\n",
    "    u_by_uuid.drop(u_by_uuid[u_by_uuid[9].isnull()].index, inplace=True)\n",
    "\n",
    "    \"\"\"Some data cleaning\"\"\"\n",
    "    # clean sex\n",
    "    value_counts = u_by_uuid[5].value_counts()\n",
    "    u_by_uuid[5] = u_by_uuid[5].map(lambda x: cleaning_filter(x, value_counts.index[:4], value_counts.index[0]))\n",
    "\n",
    "    # clean platform\n",
    "    u_by_uuid[6] = u_by_uuid[6].map(lambda x: str(x))\n",
    "    value_counts = u_by_uuid[6].value_counts()\n",
    "    u_by_uuid[6] = u_by_uuid[6].map(lambda x: cleaning_filter(x, value_counts.index[:3], '0'))\n",
    "\n",
    "    # clean status\n",
    "    u_by_uuid[7] = u_by_uuid[7].map(lambda x: str(x))\n",
    "    u_by_uuid[7] = u_by_uuid[7].map(lambda x: cleaning_filter(x, ['0'], '1'))\n",
    "\n",
    "    # clean ucid\n",
    "    u_by_uuid[8] = u_by_uuid[8].map(lambda x: str(x))\n",
    "\n",
    "    \"\"\"some processing about ucid\"\"\"\n",
    "    # clean ucid\n",
    "    u_by_uuid[10] = u_by_uuid[10].map(ucid_cleaner)\n",
    "    ucids = []\n",
    "    for each in u_by_uuid[10]:\n",
    "        ucids += each\n",
    "    dictinct_ucids = list(set(ucids))\n",
    "\n",
    "    # Begin feature engineering\n",
    "    grouped_by_u = u_by_uuid.groupby([1])\n",
    "    \n",
    "    userbase_dict = {}\n",
    "    for each in grouped_by_u.groups:\n",
    "        \n",
    "        index_list = grouped_by_u.groups[each]\n",
    "        data_frame = u_by_uuid.loc[index_list]\n",
    "        \n",
    "        try:\n",
    "            #[0] uid\n",
    "            temp = [len(index_list)]\n",
    "\n",
    "            #[1] reg_ip\n",
    "            temp.append(data_frame[2].nunique())\n",
    "\n",
    "            #[2] has signature or not\n",
    "            temp.append(int(sum(data_frame[3].isnull()) > 0))\n",
    "\n",
    "\n",
    "            #[3] has nickname or not\n",
    "            #nn = data_frame['4'].map(lambda x: x == 'None')\n",
    "            temp.append(int(sum(data_frame[4].map(lambda x: x == 'None')) > 0))\n",
    "\n",
    "            #[4] sex majority -- One-Hot?\n",
    "            temp.append(str(data_frame[5].value_counts().index[0]))\n",
    "            #[5] sex unique count\n",
    "            temp.append(data_frame[5].nunique())\n",
    "\n",
    "            #[6] platform majority -- One-Hot ?\n",
    "            temp.append(str(data_frame[6].value_counts().index[0]))\n",
    "            #[7] platform unique count\n",
    "            temp.append(data_frame[6].nunique())\n",
    "\n",
    "            #[8] ucid majority -- One-hot ?\n",
    "            temp.append(str(data_frame[8].value_counts().index[0]))\n",
    "            #[9] ucid unique count\n",
    "            temp.append(data_frame[8].nunique())\n",
    "\n",
    "            #reg time stuff\n",
    "            reg_time = data_frame[9].map(time_str2int)\n",
    "            #[10] reg time max\n",
    "            temp.append(max(reg_time))\n",
    "            #[11] reg time min\n",
    "            temp.append(min(reg_time))\n",
    "            #[12] reg time span\n",
    "            temp.append(max(reg_time) - min(reg_time))\n",
    "            #[13] reg time mean\n",
    "            temp.append(reg_time.mean())\n",
    "            #[14] reg time mid\n",
    "            temp.append(reg_time.quantile(0.5))\n",
    "            #[15] reg time std\n",
    "            temp.append(np.std(reg_time))\n",
    "\n",
    "\n",
    "            #[16] group: number of groups\n",
    "            temp.append(sum(data_frame[10].map(lambda x: len(x))) )\n",
    "            #[17] group: dummy\n",
    "            temp.append(int(temp[len(temp)-1] > 0))\n",
    "\n",
    "            \"\"\"TODO: a huge feature line of ucid down in the bottom\"\"\"\n",
    "\n",
    "            #[18] name\n",
    "            temp.append(int(sum(data_frame[11].map(lambda x: x != 'None')) > 0))\n",
    "\n",
    "            #[19-25] dummy\n",
    "            for i in range(12, 19):\n",
    "                temp.append(int(sum(data_frame[i]) > 0))\n",
    "\n",
    "            \"\"\"the huge line promised above\"\"\"\n",
    "            df_ucids = []\n",
    "            for ucid_list in data_frame[10]:\n",
    "                df_ucids += ucid_list\n",
    "            ucid_feature = [0] * len(dictinct_ucids)\n",
    "            for i, e in enumerate(dictinct_ucids):\n",
    "                if e in df_ucids:\n",
    "                    ucid_feature[i] += 1\n",
    "\n",
    "            temp += ucid_feature\n",
    "\n",
    "            userbase_dict[each] = temp\n",
    "\n",
    "        except:\n",
    "            e = sys.exc_info()[0]\n",
    "            print data_frame\n",
    "            print e\n",
    "            break\n",
    "\n",
    "    return userbase_dict\n",
    "\n",
    "\n",
    "def feature_event(filename):\n",
    "\n",
    "    # Get logs within the time range\n",
    "    t = pd.read_csv(filename, sep='\\t', header = None)\n",
    "    t1 = t[t[2] >= time_start]\n",
    "    data_all = t1[t1[2] <= time_end]\n",
    "\n",
    "    # binning whole logs in periods as a big dict()\n",
    "    whole_dict = {i : {} for i in range(n_period)}\n",
    "    # for each log\n",
    "    for log in data_all.iterrows():\n",
    "        # find its binned period\n",
    "        idx = int(math.floor((log[1][2] - time_start)/period))\n",
    "\n",
    "        if log[1][0] not in whole_dict[idx]:\n",
    "            whole_dict[idx][log[1][0]] = []\n",
    "\n",
    "        # append uuid, event id, and timestamp to the list\n",
    "        whole_dict[idx][log[1][0]].append((log[1][1], log[1][2]))\n",
    "\n",
    "    return whole_dict\n",
    "\n",
    "def get_labels(whole_dict):\n",
    "\n",
    "    # creating labels for churn = 1, stay = 0\n",
    "    labels = {i : {} for i in range(n_period)}\n",
    "    #for each period\n",
    "    for i in range(n_period - 1):\n",
    "        # for each uuid\n",
    "        for uuid in whole_dict[i]:\n",
    "            # check if the uuid appears in the next period, if yes-> stay; no-> churn\n",
    "            if uuid in whole_dict[i + 1]:\n",
    "                labels[i][uuid] = 0\n",
    "            else:\n",
    "                labels[i][uuid] = 1\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (3,6,7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (6,7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "u0 = pd.read_csv(\"/data/yulun/timeline/user_base_0.txt\", sep='\\t', header = None)\n",
    "u1 = pd.read_csv(\"/data/yulun/timeline/user_base_1.txt\", sep='\\t', header = None)\n",
    "u2 = pd.read_csv(\"/data/yulun/timeline/user_base_2.txt\", sep='\\t', header = None)\n",
    "u3 = pd.read_csv(\"/data/yulun/timeline/user_base_3.txt\", sep='\\t', header = None)\n",
    "u4 = pd.read_csv(\"/data/yulun/timeline/user_base_4.txt\", sep='\\t', header = None)\n",
    "u5 = pd.read_csv(\"/data/yulun/timeline/user_base_5.txt\", sep='\\t', header = None)\n",
    "u6 = pd.read_csv(\"/data/yulun/timeline/user_base_6.txt\", sep='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u = u0.append(u1).append(u2).append(u3).append(u4).append(u5).append(u6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_uuids(filename):\n",
    "    # Get logs within the time range\n",
    "    t = pd.read_csv(filename, sep='\\t', header = None)\n",
    "    t1 = t[t[2] >= time_start]\n",
    "    data_all = t1[t1[2] <= time_end]\n",
    "\n",
    "    grouped_by_uuid = data_all.groupby([0])\n",
    "    uuids = grouped_by_uuid.groups.keys()\n",
    "\n",
    "    return uuids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uuid_list = get_uuids(\"/data/yulun/timeline/timeline_event_gpapp.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userbase_dict = feature_userbase(u, uuid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_obj(userbase_dict, 'userbase_dict_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_uuid2uid(userbase_dataframe, uuid_list):\n",
    "    # TODO\n",
    "    u_by_uuid = userbase_dataframe[userbase_dataframe[1].isin(set(uuid_list))]\n",
    "    u_by_uuid = u_by_uuid[u_by_uuid[1]!= 'cfcd208495d565ef66e7dff9f98764da']\n",
    "    uuid2uid = {}\n",
    "    for each in u_by_uuid.iterrows():\n",
    "        if each[1][1] not in uuid2uid:\n",
    "            uuid2uid[each[1][1]] = []\n",
    "        uuid2uid[each[1][1]].append(each[1][0])\n",
    "    return uuid2uid\n",
    "\n",
    "def get_uid2uuid(userbase_dataframe, uuid_list):\n",
    "    u_by_uuid = userbase_dataframe[userbase_dataframe[1].isin(set(uuid_list))]\n",
    "    u_by_uuid = u_by_uuid[u_by_uuid[1]!= 'cfcd208495d565ef66e7dff9f98764da']\n",
    "    uid2uuid = {}\n",
    "    for each in u_by_uuid.iterrows():\n",
    "        if each[1][0] not in uid2uuid:\n",
    "            uid2uuid[each[1][0]] = []\n",
    "        uid2uuid[each[1][0]].append(each[1][1])\n",
    "    return uid2uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uuid2uid = get_uuid2uid(u, uuid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uid2uuid = get_uid2uuid(u, uuid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    for each in uid2uuid:\n",
    "        if len(uid2uuid[each]) > 1:\n",
    "            print \"Found one-to-many uid to uuid relationship, but I ignored it for simplicity.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "e = pd.read_csv('/data/yulun/timeline/expenditure_timeline.txt', sep='\\t', header = None)\n",
    "exp = e[e[0].isin(set(uid2uuid.keys()))]\n",
    "exp[-1] = exp[0].map(lambda x: uid2uuid[x][0])\n",
    "exp_by_uuid = exp.groupby([-1])\n",
    "\n",
    "expenditure_dict = {}\n",
    "for each in exp_by_uuid.groups:\n",
    "    index_list = exp_by_uuid.groups[each]\n",
    "    data_frame = exp.loc[index_list]\n",
    "\n",
    "    reg = []\n",
    "    rec = []\n",
    "    pay = []\n",
    "    for row in data_frame.iterrows():\n",
    "        reg += string2list(row[1][1])\n",
    "        rec += string2list(row[1][2])\n",
    "        pay += string2list(row[1][3])\n",
    "    reg = pd.DataFrame(reg)\n",
    "    rec = pd.DataFrame(rec)\n",
    "    pay = pd.DataFrame(pay)\n",
    "\n",
    "\n",
    "    \"\"\"reg\"\"\"\n",
    "    reg = reg[reg[3]!='0']\n",
    "    try: # no reg means no rec or pay\n",
    "        #[0] #uid\n",
    "        temp = [len(index_list)]\n",
    "        #[1] #games\n",
    "        temp.append(len(reg[0]))\n",
    "        #[2] # unique games\n",
    "        temp.append(len(reg[1].unique()))\n",
    "        #[3] # unique cid\n",
    "        temp.append(len(reg[2].unique()))\n",
    "        #[4] # unique game_uid\n",
    "        temp.append(len(reg[4].unique()))\n",
    "        #[5] # unique ucid\n",
    "        temp.append(len(reg[5].unique()))\n",
    "\n",
    "        reg_time = reg[3].map(time_str2int)\n",
    "        #[6] max reg time\n",
    "        temp.append(max(reg_time))\n",
    "        #[7] min reg time\n",
    "        temp.append(min(reg_time))\n",
    "        #[8] reg time span\n",
    "        temp.append(max(reg_time) - min(reg_time))\n",
    "        #[9] reg time mean\n",
    "        temp.append(reg_time.mean())\n",
    "        #[10] reg time mid\n",
    "        temp.append(reg_time.quantile(0.5))\n",
    "        #[11] reg time std\n",
    "        temp.append(np.std(reg_time))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    \"\"\"rec\"\"\"\n",
    "    rec = rec[rec[2]!='0']\n",
    "    if len(rec) == 0:\n",
    "        temp += [np.nan] * 12\n",
    "    else:\n",
    "        #[12] # rec\n",
    "        temp.append(len(rec[0]))\n",
    "        #[13] # unique games\n",
    "        temp.append(len(rec[0].unique()))\n",
    "        #[14] # unique types\n",
    "        temp.append(len(rec[1].unique()))\n",
    "        #[15] # unique cid\n",
    "        temp.append(len(rec[3].unique()))\n",
    "        #[16] # unique item\n",
    "        temp.append(len(rec[4].unique()))    \n",
    "        #[17] # unique appid\n",
    "        temp.append(len(rec[5].unique()))  \n",
    "        #[18] # unique pay_from\n",
    "        temp.append(len(rec[6].unique()))  \n",
    "\n",
    "        rec_time = rec[2].map(time_str2int)\n",
    "        #[19] max reg time\n",
    "        temp.append(max(rec_time))\n",
    "        #[20] min reg time\n",
    "        temp.append(min(rec_time))\n",
    "        #[21] reg time span\n",
    "        temp.append(max(rec_time) - min(rec_time))\n",
    "        #[22] reg time mean\n",
    "        temp.append(rec_time.mean())\n",
    "        #[23] reg time mid\n",
    "        temp.append(rec_time.quantile(0.5))\n",
    "        #[24] reg time std\n",
    "        temp.append(np.std(rec_time))\n",
    "\n",
    "    pay = pay[pay[2]!='0']\n",
    "    if len(pay) == 0:\n",
    "        temp += [np.nan] * 11\n",
    "    else:\n",
    "        #[25] # payments\n",
    "        temp.append(len(pay[0]))\n",
    "        #[26] # unique games\n",
    "        temp.append(len(pay[0].unique()))\n",
    "        #[27] # unique cid\n",
    "        temp.append(len(pay[1].unique()))\n",
    "        #[28] # unique appid\n",
    "        temp.append(len(pay[3].unique()))\n",
    "        #[29] # unique item\n",
    "        temp.append(len(pay[4].unique()))    \n",
    "        #[30] # unique porder\n",
    "        temp.append(len(pay[5].unique()))  \n",
    "\n",
    "\n",
    "        pay_time = pay[2].map(time_str2int)\n",
    "        #[31] max reg time\n",
    "        temp.append(max(pay_time))\n",
    "        #[32] min reg time\n",
    "        temp.append(min(pay_time))\n",
    "        #[33] reg time span\n",
    "        temp.append(max(pay_time) - min(pay_time))\n",
    "        #[34] reg time mean\n",
    "        temp.append(pay_time.mean())\n",
    "        #[35] reg time mid\n",
    "        temp.append(pay_time.quantile(0.5))\n",
    "        #[36] reg time std\n",
    "        temp.append(np.std(pay_time))\n",
    "\n",
    "    expenditure_dict[each] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_obj(expenditure_dict, 'expenditure_dict_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Done preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whole_dict = load_obj('whole_dict_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_dict = load_obj('expenditure_dict_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_dict = load_obj('userbase_dict_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = get_labels(whole_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eventids = get_eventids('/data/yulun/timeline/timeline_event_gpapp.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = []\n",
    "num_handcraft_feature = 105\n",
    "for i in range(n_period - 2):\n",
    "    for uuid in whole_dict[i]:\n",
    "        e_len = len(eventids)\n",
    "\n",
    "        row = np.zeros(e_len + num_handcraft_feature)\n",
    "\n",
    "        # label\n",
    "        row[0] = labels[i][uuid]\n",
    "\n",
    "        times = []\n",
    "        times_diff = []\n",
    "        for each in whole_dict[i][uuid]:\n",
    "            eid = each[0]\n",
    "            ts = each[1]\n",
    "            idx = eventids.index(eid)\n",
    "            # [0] - [len(eventid)] event feature\n",
    "            row[idx + 1] += 1\n",
    "\n",
    "            times.append(ts)\n",
    "            times_diff.append(ts - (time_start + period*(i)))\n",
    "\n",
    "        # add handcraft features here\n",
    "        \"\"\"time features\"\"\"\n",
    "        # time\n",
    "        row[e_len + 1] = max(times)\n",
    "        row[e_len + 2] = min(times)\n",
    "        row[e_len + 3] = max(times) - min(times)\n",
    "        row[e_len + 4] = np.mean(times)\n",
    "        row[e_len + 5] = np.percentile(times, 50)\n",
    "        row[e_len + 6] = np.std(times)\n",
    "        # time_diff\n",
    "        row[e_len + 7] = max(times_diff)\n",
    "        row[e_len + 8] = min(times_diff)\n",
    "        row[e_len + 9] = np.mean(times_diff)\n",
    "        row[e_len + 10] = np.percentile(times_diff, 50)\n",
    "\n",
    "        # userbase integrated time features\n",
    "        try:\n",
    "            row[e_len + 11] = max(times) - user_dict[uuid][10]\n",
    "            row[e_len + 12] = max(times) - user_dict[uuid][11]\n",
    "            row[e_len + 13] = max(times) - user_dict[uuid][13]\n",
    "            row[e_len + 14] = max(times) - user_dict[uuid][14]\n",
    "            row[e_len + 15] = min(times) - user_dict[uuid][10]\n",
    "            row[e_len + 16] = min(times) - user_dict[uuid][11]\n",
    "            row[e_len + 17] = min(times) - user_dict[uuid][13]\n",
    "            row[e_len + 18] = min(times) - user_dict[uuid][14]\n",
    "            row[e_len + 19] = np.percentile(times, 50) - user_dict[uuid][10]\n",
    "            row[e_len + 20] = np.percentile(times, 50) - user_dict[uuid][11]\n",
    "            row[e_len + 21] = np.percentile(times, 50) - user_dict[uuid][13]\n",
    "            row[e_len + 22] = np.percentile(times, 50) - user_dict[uuid][14]\n",
    "            row[e_len + 23] = np.mean(times) - user_dict[uuid][10]\n",
    "            row[e_len + 24] = np.mean(times) - user_dict[uuid][11]\n",
    "            row[e_len + 25] = np.mean(times) - user_dict[uuid][13]\n",
    "            row[e_len + 26] = np.mean(times) - user_dict[uuid][14]\n",
    "            row[e_len + 27] = (time_start + period*(i)) - user_dict[uuid][10]\n",
    "            row[e_len + 28] = (time_start + period*(i)) - user_dict[uuid][11]\n",
    "            row[e_len + 29] = (time_start + period*(i)) - user_dict[uuid][13]\n",
    "            row[e_len + 30] = (time_start + period*(i)) - user_dict[uuid][14]\n",
    "        except:\n",
    "            row[e_len + 11 : e_len + 31] = np.nan\n",
    "\n",
    "        # expenditure integrated time features\n",
    "        try:\n",
    "            row[e_len + 31] = max(times) - exp_dict[uuid][6]\n",
    "            row[e_len + 32] = max(times) - exp_dict[uuid][7]\n",
    "            row[e_len + 33] = max(times) - exp_dict[uuid][9]\n",
    "            row[e_len + 34] = max(times) - exp_dict[uuid][10]\n",
    "            row[e_len + 35] = min(times) - exp_dict[uuid][6]\n",
    "            row[e_len + 36] = min(times) - exp_dict[uuid][7]\n",
    "            row[e_len + 37] = min(times) - exp_dict[uuid][9]\n",
    "            row[e_len + 38] = min(times) - exp_dict[uuid][10]\n",
    "            row[e_len + 39] = np.percentile(times, 50) - exp_dict[uuid][6]\n",
    "            row[e_len + 40] = np.percentile(times, 50) - exp_dict[uuid][7]\n",
    "            row[e_len + 41] = np.percentile(times, 50) - exp_dict[uuid][9]\n",
    "            row[e_len + 42] = np.percentile(times, 50) - exp_dict[uuid][10]\n",
    "            row[e_len + 43] = np.mean(times) - exp_dict[uuid][6]\n",
    "            row[e_len + 44] = np.mean(times) - exp_dict[uuid][7]\n",
    "            row[e_len + 45] = np.mean(times) - exp_dict[uuid][9]\n",
    "            row[e_len + 46] = np.mean(times) - exp_dict[uuid][10]\n",
    "            row[e_len + 47] = (time_start + period*(i)) - exp_dict[uuid][6]\n",
    "            row[e_len + 48] = (time_start + period*(i)) - exp_dict[uuid][7]\n",
    "            row[e_len + 49] = (time_start + period*(i)) - exp_dict[uuid][9]\n",
    "            row[e_len + 50] = (time_start + period*(i)) - exp_dict[uuid][10]\n",
    "        except:\n",
    "            row[e_len + 31 : e_len + 51] = np.nan\n",
    "\n",
    "        try:\n",
    "            row[e_len + 51] = max(times) - exp_dict[uuid][19]\n",
    "            row[e_len + 52] = max(times) - exp_dict[uuid][20]\n",
    "            row[e_len + 53] = max(times) - exp_dict[uuid][22]\n",
    "            row[e_len + 54] = max(times) - exp_dict[uuid][23]\n",
    "            row[e_len + 55] = min(times) - exp_dict[uuid][19]\n",
    "            row[e_len + 56] = min(times) - exp_dict[uuid][20]\n",
    "            row[e_len + 57] = min(times) - exp_dict[uuid][22]\n",
    "            row[e_len + 58] = min(times) - exp_dict[uuid][23]\n",
    "            row[e_len + 59] = np.percentile(times, 50) - exp_dict[uuid][19]\n",
    "            row[e_len + 60] = np.percentile(times, 50) - exp_dict[uuid][20]\n",
    "            row[e_len + 51] = np.percentile(times, 50) - exp_dict[uuid][22]\n",
    "            row[e_len + 62] = np.percentile(times, 50) - exp_dict[uuid][23]\n",
    "            row[e_len + 63] = np.mean(times) - exp_dict[uuid][19]\n",
    "            row[e_len + 64] = np.mean(times) - exp_dict[uuid][20]\n",
    "            row[e_len + 65] = np.mean(times) - exp_dict[uuid][22]\n",
    "            row[e_len + 66] = np.mean(times) - exp_dict[uuid][23]\n",
    "            row[e_len + 67] = (time_start + period*(i)) - exp_dict[uuid][19]\n",
    "            row[e_len + 68] = (time_start + period*(i)) - exp_dict[uuid][20]\n",
    "            row[e_len + 69] = (time_start + period*(i)) - exp_dict[uuid][22]\n",
    "            row[e_len + 70] = (time_start + period*(i)) - exp_dict[uuid][23]\n",
    "        except:\n",
    "            row[e_len + 51 : e_len + 71] = np.nan\n",
    "\n",
    "        try:\n",
    "            row[e_len + 71] = max(times) - exp_dict[uuid][31]\n",
    "            row[e_len + 72] = max(times) - exp_dict[uuid][32]\n",
    "            row[e_len + 73] = max(times) - exp_dict[uuid][34]\n",
    "            row[e_len + 74] = max(times) - exp_dict[uuid][35]\n",
    "            row[e_len + 75] = min(times) - exp_dict[uuid][31]\n",
    "            row[e_len + 76] = min(times) - exp_dict[uuid][32]\n",
    "            row[e_len + 77] = min(times) - exp_dict[uuid][34]\n",
    "            row[e_len + 78] = min(times) - exp_dict[uuid][35]\n",
    "            row[e_len + 79] = np.percentile(times, 50) - exp_dict[uuid][31]\n",
    "            row[e_len + 80] = np.percentile(times, 50) - exp_dict[uuid][32]\n",
    "            row[e_len + 81] = np.percentile(times, 50) - exp_dict[uuid][34]\n",
    "            row[e_len + 82] = np.percentile(times, 50) - exp_dict[uuid][35]\n",
    "            row[e_len + 83] = np.mean(times) - exp_dict[uuid][31]\n",
    "            row[e_len + 84] = np.mean(times) - exp_dict[uuid][32]\n",
    "            row[e_len + 85] = np.mean(times) - exp_dict[uuid][34]\n",
    "            row[e_len + 86] = np.mean(times) - exp_dict[uuid][35]\n",
    "            row[e_len + 87] = (time_start + period*(i)) - exp_dict[uuid][31]\n",
    "            row[e_len + 88] = (time_start + period*(i)) - exp_dict[uuid][32]\n",
    "            row[e_len + 89] = (time_start + period*(i)) - exp_dict[uuid][34]\n",
    "            row[e_len + 90] = (time_start + period*(i)) - exp_dict[uuid][35]\n",
    "        except:\n",
    "            row[e_len + 71 : e_len + 91] = np.nan\n",
    "\n",
    "        \"\"\"Event features\"\"\"\n",
    "        # [57+] #events\n",
    "        row[e_len + 91] = len(whole_dict[i][uuid])\n",
    "        # break into 2 bins\n",
    "        row[e_len + 92] = len(filter(lambda x: x[1] >= (time_start + period*(i)) and x[1] < (time_start + period*(i+0.5)), whole_dict[i][uuid]))\n",
    "        row[e_len + 93] = len(filter(lambda x: x[1] >= (time_start + period*(i+0.5)) and x[1] < (time_start + period*(i+1)), whole_dict[i][uuid]))\n",
    "        # break into 4 bins\n",
    "        row[e_len + 94] = len(filter(lambda x: x[1] >= (time_start + period*(i)) and x[1] < (time_start + period*(i+0.25)), whole_dict[i][uuid]))\n",
    "        row[e_len + 95] = len(filter(lambda x: x[1] >= (time_start + period*(i+0.25)) and x[1] < (time_start + period*(i+0.5)), whole_dict[i][uuid]))\n",
    "        row[e_len + 96] = len(filter(lambda x: x[1] >= (time_start + period*(i+0.5)) and x[1] < (time_start + period*(i+0.75)), whole_dict[i][uuid]))\n",
    "        row[e_len + 97] = len(filter(lambda x: x[1] >= (time_start + period*(i+0.75)) and x[1] < (time_start + period*(i+1)), whole_dict[i][uuid]))\n",
    "        # break into 7 bins\n",
    "        row[e_len + 98] = len(filter(lambda x: x[1] >= (time_start + period*(i)) and x[1] < (time_start + period*(i+1/7.0)), whole_dict[i][uuid]))\n",
    "        row[e_len + 99] = len(filter(lambda x: x[1] >= (time_start + period*(i+1/7.0)) and x[1] < (time_start + period*(i+2/7.0)), whole_dict[i][uuid]))\n",
    "        row[e_len + 100] = len(filter(lambda x: x[1] >= (time_start + period*(i+2/7.0)) and x[1] < (time_start + period*(i+3/7.0)), whole_dict[i][uuid]))\n",
    "        row[e_len + 101] = len(filter(lambda x: x[1] >= (time_start + period*(i+3/7.0)) and x[1] < (time_start + period*(i+4/7.0)), whole_dict[i][uuid]))\n",
    "        row[e_len + 102] = len(filter(lambda x: x[1] >= (time_start + period*(i+4/7.0)) and x[1] < (time_start + period*(i+5/7.0)), whole_dict[i][uuid]))\n",
    "        row[e_len + 103] = len(filter(lambda x: x[1] >= (time_start + period*(i+5/7.0)) and x[1] < (time_start + period*(i+6/7.0)), whole_dict[i][uuid]))\n",
    "        row[e_len + 104] = len(filter(lambda x: x[1] >= (time_start + period*(i+6/7.0)) and x[1] < (time_start + period*(i+1)), whole_dict[i][uuid]))\n",
    "\n",
    "        \"\"\"features.append(row)\"\"\"\n",
    "        features.append((uuid, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exp_dict[exp_dict.keys()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    ret = []\n",
    "    for each in features:\n",
    "        temp = each[1].tolist()\n",
    "        if each[0] in user_dict:\n",
    "            temp += user_dict[each[0]]\n",
    "        else:\n",
    "            temp += ([np.nan]*145)\n",
    "        if each[0] in exp_dict:\n",
    "            temp += exp_dict[each[0]]\n",
    "        else:\n",
    "            temp += ([np.nan]*37)\n",
    "        ret.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final = pd.DataFrame(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_obj(final, 'final_augment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final = load_obj('final_augment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final[308] = final[308].map(lambda x: ['None', '0', '1', '2'].index(x) if x in ['None', '0', '1', '2'] else 0)\n",
    "final[310] = final[310].map(lambda x: [ '0', '102', '101'].index(x) if x in [ '0', '102', '101'] else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = range(1, final.shape[1])\n",
    "\n",
    "data = final[indices]\n",
    "target = final[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127418, 702)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill NaN with mean, and train model with full feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer()\n",
    "data = imputer.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data, target, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300, max_features=400).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.814883848689\n",
      "0.75531552515\n",
      "0.871916701736\n",
      "0.836628891494\n",
      "0.910312375985\n",
      "Confusion Matrix: \n",
      "[[ 9419  6271]\n",
      " [ 3164 32114]]\n",
      "false positive: 6271\n",
      "false negative: 3164\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "print \"Below are the accuracy, AUC, F1 score, precision, and recall: \"\n",
    "print clf.score(X_test, y_test)\n",
    "print roc_auc_score(y_test, y_pred)\n",
    "print f1_score(y_test, y_pred)\n",
    "print precision_score(y_test, y_pred)\n",
    "print recall_score(y_test, y_pred)\n",
    "\n",
    "print \"Confusion Matrix: \"\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print cm\n",
    "#false positive\n",
    "print 'false positive: ' + str(cm[0][1])\n",
    "#false negative\n",
    "print 'false negative: ' + str(cm[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### fill NaN with -999, and train with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test \n",
    "final.fillna(value = -999, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data, target, test_size=0.4, random_state=0)\n",
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300, max_features=400).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.813981321614\n",
      "0.754097343395\n",
      "0.871323679103\n",
      "0.835872197485\n",
      "0.909915528091\n",
      "Confusion Matrix: \n",
      "[[ 9387  6303]\n",
      " [ 3178 32100]]\n",
      "false positive: 6303\n",
      "false negative: 3178\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "print \"Below are the accuracy, AUC, F1 score, precision, and recall: \"\n",
    "print clf.score(X_test, y_test)\n",
    "print roc_auc_score(y_test, y_pred)\n",
    "print f1_score(y_test, y_pred)\n",
    "print precision_score(y_test, y_pred)\n",
    "print recall_score(y_test, y_pred)\n",
    "\n",
    "print \"Confusion Matrix: \"\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print cm\n",
    "#false positive\n",
    "print 'false positive: ' + str(cm[0][1])\n",
    "#false negative\n",
    "print 'false negative: ' + str(cm[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### fill NaNs with 0, train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test \n",
    "final.fillna(value = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data, target, test_size=0.4, random_state=0)\n",
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300, max_features=400).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.814452205305\n",
      "0.754455193026\n",
      "0.871687719631\n",
      "0.835992192583\n",
      "0.910567492488\n",
      "Confusion Matrix: \n",
      "[[ 9388  6302]\n",
      " [ 3155 32123]]\n",
      "false positive: 6302\n",
      "false negative: 3155\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "print \"Below are the accuracy, AUC, F1 score, precision, and recall: \"\n",
    "print clf.score(X_test, y_test)\n",
    "print roc_auc_score(y_test, y_pred)\n",
    "print f1_score(y_test, y_pred)\n",
    "print precision_score(y_test, y_pred)\n",
    "print recall_score(y_test, y_pred)\n",
    "\n",
    "print \"Confusion Matrix: \"\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print cm\n",
    "#false positive\n",
    "print 'false positive: ' + str(cm[0][1])\n",
    "#false negative\n",
    "print 'false negative: ' + str(cm[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only use event features which contain very few nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "      <th>301</th>\n",
       "      <th>302</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   293  294    295  \\\n",
       "0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0    1.0   \n",
       "1  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0    4.0   \n",
       "2  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0    2.0   \n",
       "3  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0    1.0   \n",
       "4  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  109.0   \n",
       "\n",
       "   296  297  298  299  300    301  302  \n",
       "0  0.0  0.0  0.0  0.0  0.0    1.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0    4.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0    2.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0    1.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  109.0  0.0  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[range(303)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = range(1, 303)\n",
    "\n",
    "data = final[indices]\n",
    "target = final[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data, target, test_size=0.4, random_state=0)\n",
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300, max_features=250).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.813843980537\n",
      "0.753998131422\n",
      "0.871216439992\n",
      "0.835842275237\n",
      "0.909717104144\n",
      "Confusion Matrix: \n",
      "[[ 9387  6303]\n",
      " [ 3185 32093]]\n",
      "false positive: 6303\n",
      "false negative: 3185\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "print \"Below are the accuracy, AUC, F1 score, precision, and recall: \"\n",
    "print clf.score(X_test, y_test)\n",
    "print roc_auc_score(y_test, y_pred)\n",
    "print f1_score(y_test, y_pred)\n",
    "print precision_score(y_test, y_pred)\n",
    "print recall_score(y_test, y_pred)\n",
    "\n",
    "print \"Confusion Matrix: \"\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print cm\n",
    "#false positive\n",
    "print 'false positive: ' + str(cm[0][1])\n",
    "#false negative\n",
    "print 'false negative: ' + str(cm[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean imputation + Feature selection (k = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [259 322 323 324 325 326 328 338 356 383 397 443] are constant.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "score = f_classif(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [259 322 323 324 325 326 328 338 356 383 397 443] are constant.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "select = SelectKBest(f_classif, k = 400)\n",
    "data2 = select.fit_transform(data, target)\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data2, target, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300, max_features=250).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.812725631769\n",
      "0.750943087358\n",
      "0.870788266031\n",
      "0.833389474775\n",
      "0.911701343614\n",
      "Confusion Matrix: \n",
      "[[ 9260  6430]\n",
      " [ 3115 32163]]\n",
      "false positive: 6430\n",
      "false negative: 3115\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "print \"Below are the accuracy, AUC, F1 score, precision, and recall: \"\n",
    "print clf.score(X_test, y_test)\n",
    "print roc_auc_score(y_test, y_pred)\n",
    "print f1_score(y_test, y_pred)\n",
    "print precision_score(y_test, y_pred)\n",
    "print recall_score(y_test, y_pred)\n",
    "\n",
    "print \"Confusion Matrix: \"\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print cm\n",
    "#false positive\n",
    "print 'false positive: ' + str(cm[0][1])\n",
    "#false negative\n",
    "print 'false negative: ' + str(cm[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean imputation + Feature selection (k = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select = SelectKBest(f_classif, k = 300)\n",
    "data2 = select.fit_transform(data, target)\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data2, target, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300, max_features=250).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.81329461623\n",
      "0.753742837867\n",
      "0.870759201412\n",
      "0.835862536504\n",
      "0.908696638131\n",
      "Confusion Matrix: \n",
      "[[ 9395  6295]\n",
      " [ 3221 32057]]\n",
      "false positive: 6295\n",
      "false negative: 3221\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "print \"Below are the accuracy, AUC, F1 score, precision, and recall: \"\n",
    "print clf.score(X_test, y_test)\n",
    "print roc_auc_score(y_test, y_pred)\n",
    "print f1_score(y_test, y_pred)\n",
    "print precision_score(y_test, y_pred)\n",
    "print recall_score(y_test, y_pred)\n",
    "\n",
    "print \"Confusion Matrix: \"\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print cm\n",
    "#false positive\n",
    "print 'false positive: ' + str(cm[0][1])\n",
    "#false negative\n",
    "print 'false negative: ' + str(cm[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean imputation + Feature selection (k = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select = SelectKBest(f_classif, k = 200)\n",
    "data2 = select.fit_transform(data, target)\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data2, target, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300, max_features=200).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.812509810077\n",
      "0.751158762969\n",
      "0.870546479179\n",
      "0.833705241308\n",
      "0.910794262713\n",
      "Confusion Matrix: \n",
      "[[ 9281  6409]\n",
      " [ 3147 32131]]\n",
      "false positive: 6409\n",
      "false negative: 3147\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "print \"Below are the accuracy, AUC, F1 score, precision, and recall: \"\n",
    "print clf.score(X_test, y_test)\n",
    "print roc_auc_score(y_test, y_pred)\n",
    "print f1_score(y_test, y_pred)\n",
    "print precision_score(y_test, y_pred)\n",
    "print recall_score(y_test, y_pred)\n",
    "\n",
    "print \"Confusion Matrix: \"\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print cm\n",
    "#false positive\n",
    "print 'false positive: ' + str(cm[0][1])\n",
    "#false negative\n",
    "print 'false negative: ' + str(cm[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try other models: logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_result():\n",
    "    # Evaluation\n",
    "    print \"Below are the accuracy, AUC, F1 score, precision, and recall: \"\n",
    "    print clf.score(X_test, y_test)\n",
    "    print roc_auc_score(y_test, y_pred)\n",
    "    print f1_score(y_test, y_pred)\n",
    "    print precision_score(y_test, y_pred)\n",
    "    print recall_score(y_test, y_pred)\n",
    "\n",
    "    print \"Confusion Matrix: \"\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print cm\n",
    "    #false positive\n",
    "    print 'false positive: ' + str(cm[0][1])\n",
    "    #false negative\n",
    "    print 'false negative: ' + str(cm[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select = SelectKBest(f_classif, k = 300)\n",
    "data2 = select.fit_transform(data, target)\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data2, target, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.742956364778\n",
      "0.625112636258\n",
      "0.833830113773\n",
      "0.754539402704\n",
      "0.931742162254\n",
      "Confusion Matrix: \n",
      "[[ 4997 10693]\n",
      " [ 2408 32870]]\n",
      "false positive: 10693\n",
      "false negative: 2408\n"
     ]
    }
   ],
   "source": [
    "eval_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SGDClassifier().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.692159786533\n",
      "0.5\n",
      "0.818078519584\n",
      "0.692159786533\n",
      "1.0\n",
      "Confusion Matrix: \n",
      "[[    0 15690]\n",
      " [    0 35278]]\n",
      "false positive: 15690\n",
      "false negative: 0\n"
     ]
    }
   ],
   "source": [
    "eval_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.793007377178\n",
      "0.724649269459\n",
      "0.857870345422\n",
      "0.817432605905\n",
      "0.902517149498\n",
      "Confusion Matrix: \n",
      "[[ 8579  7111]\n",
      " [ 3439 31839]]\n",
      "false positive: 7111\n",
      "false negative: 3439\n"
     ]
    }
   ],
   "source": [
    "eval_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.773916967509\n",
      "0.731508044399\n",
      "0.837523441576\n",
      "0.833235137334\n",
      "0.841856114292\n",
      "Confusion Matrix: \n",
      "[[ 9746  5944]\n",
      " [ 5579 29699]]\n",
      "false positive: 5944\n",
      "false negative: 5579\n"
     ]
    }
   ],
   "source": [
    "eval_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.757651859991\n",
      "0.715671130564\n",
      "0.824928423619\n",
      "0.824951808595\n",
      "0.824905039968\n",
      "Confusion Matrix: \n",
      "[[ 9515  6175]\n",
      " [ 6177 29101]]\n",
      "false positive: 6175\n",
      "false negative: 6177\n"
     ]
    }
   ],
   "source": [
    "eval_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.691728143149\n",
      "0.499705885233\n",
      "0.817772726218\n",
      "0.692034390704\n",
      "0.999348035603\n",
      "Confusion Matrix: \n",
      "[[    1 15689]\n",
      " [   23 35255]]\n",
      "false positive: 15689\n",
      "false negative: 23\n"
     ]
    }
   ],
   "source": [
    "clf = SVC().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "eval_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.307840213467\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Confusion Matrix: \n",
      "[[15690     0]\n",
      " [35278     0]]\n",
      "false positive: 0\n",
      "false negative: 35278\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "eval_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    20755\n",
       "0.0      142\n",
       "Name: 306, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[final[0]==0][306].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18032"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(final[final[0]==0][306].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     88040\n",
       "1.0       295\n",
       "2.0        75\n",
       "3.0        30\n",
       "5.0        12\n",
       "4.0        10\n",
       "7.0         7\n",
       "10.0        6\n",
       "6.0         4\n",
       "12.0        2\n",
       "9.0         2\n",
       "88.0        1\n",
       "69.0        1\n",
       "11.0        1\n",
       "18.0        1\n",
       "32.0        1\n",
       "8.0         1\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[final[0]==1][2].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53696"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(final[final[0]==1][306].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "churn_null_count = [sum(final[final[0]==1][i].isnull()) for i in range(final.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stay_null_count = [sum(final[final[0]==0][i].isnull()) for i in range(final.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "churn_idx = [i for i, e in enumerate(churn_null_count) if e == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stay_idx = [i for i, e in enumerate(stay_null_count) if e == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, e in enumerate(churn_idx):\n",
    "    if stay_idx[i] != e:\n",
    "        print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 308,\n",
       " 310]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uuids_gpsdk = load_obj('mar_uuids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "555579"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uuids_gpsdk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uuid_in_userbase = u[1].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "uuid_in_userbase = set(uuid_in_userbase)\n",
    "for each in uuids_gpsdk:\n",
    "    if each in uuid_in_userbase:\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329627"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110334"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uuid_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only use features that do not contain NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = final[churn_idx]\n",
    "del data[0]\n",
    "target = final[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data, target, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300, max_features=200).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.810155391618\n",
      "0.747759334209\n",
      "0.869048585736\n",
      "0.831529058324\n",
      "0.910113952038\n",
      "Confusion Matrix: \n",
      "[[ 9185  6505]\n",
      " [ 3171 32107]]\n",
      "false positive: 6505\n",
      "false negative: 3171\n"
     ]
    }
   ],
   "source": [
    "eval_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove data points that contain nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row_idx = final[485].notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = final.loc[row_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data[range(1, 486)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = final.loc[row_idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data, target, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300, max_features=400).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.748764175632\n",
      "0.74856214686\n",
      "0.755032605614\n",
      "0.752259887006\n",
      "0.757825839499\n",
      "Confusion Matrix: \n",
      "[[2487  877]\n",
      " [ 851 2663]]\n",
      "false positive: 877\n",
      "false negative: 851\n"
     ]
    }
   ],
   "source": [
    "eval_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17193, 485)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from operator import itemgetter\n",
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print \"Model with rank: {0}\".format(i + 1)\n",
    "        print \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores))\n",
    "        print \"Parameters: {0}\".format(score.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [259 322 323 324 325 326 328 338 356 383 397 443] are constant.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "select = SelectKBest(f_classif, k = 400)\n",
    "data2 = select.fit_transform(data, target)\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data2, target, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = { 'loss': ['exponential'],\n",
    "               'learning_rate':[0.1, 0.2],\n",
    "               'n_estimators':[100, 300, 500],\n",
    "               'max_depth':[3, 7],\n",
    "               'max_features':[20, 200, 400],\n",
    "               'random_state':[0],\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "clf = GradientBoostingClassifier()\n",
    "grid_search = RandomizedSearchCV(clf, param_distributions=param_grid, n_iter=20)\n",
    "grid_search.fit(data2, target)\n",
    "print time()-start\n",
    "report(grid_search.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_aug1 = Binarizer().fit_transform(final[range(1,200)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127418, 199)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_aug1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_aug2 = final[448].notnull().map(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_aug3 = final[479].notnull().map(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_aug4 = Binarizer().fit_transform(final[range(290,304)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_aug5 = final[202].map(lambda x: int(x <= 86400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_aug6 = final[205].map(lambda x: int(x <= 86400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x10a1e8910>]], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b15a8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(filter(lambda x: x <= 1000,final[202])).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10c1b1990>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEACAYAAAByG0uxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMTOzxtyJmJlZY+5EzMysMXciZmbW2P8HaZkUp13+C8oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c31ae50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final[209].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127418, 14)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_aug4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final[range(486,685)] = pd.DataFrame(final_aug1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final[range(685,699)] = pd.DataFrame(final_aug4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final[699] = pd.DataFrame(final_aug2)\n",
    "final[700] = pd.DataFrame(final_aug3)\n",
    "final[701] = pd.DataFrame(final_aug5)\n",
    "final[702] = pd.DataFrame(final_aug6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final[703] = final[308].map(lambda x : int(x == 0))\n",
    "final[704] = final[308].map(lambda x : int(x == 1))\n",
    "final[705] = final[308].map(lambda x : int(x == 2))\n",
    "final[706] = final[308].map(lambda x : int(x == 3))\n",
    "final[707] = final[310].map(lambda x : int(x == 0))\n",
    "final[708] = final[310].map(lambda x : int(x == 1))\n",
    "final[709] = final[310].map(lambda x : int(x == 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_obj(final, 'final_aug_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127418, 710)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data, target, test_size=0.4, random_state=0)\n",
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300, max_features=700).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.813137654999\n",
      "0.752443935163\n",
      "0.870871522317\n",
      "0.834658766048\n",
      "0.910369068541\n",
      "Confusion Matrix: \n",
      "[[ 9328  6362]\n",
      " [ 3162 32116]]\n",
      "false positive: 6362\n",
      "false negative: 3162\n"
     ]
    }
   ],
   "source": [
    "eval_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "final_aug7 = OneHotEncoder().fit_transform(final[308])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x127418 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 127418 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_aug7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final = load_obj('final_aug_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = range(1, final.shape[1])\n",
    "\n",
    "data = final[indices]\n",
    "target = final[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer()\n",
    "data = imputer.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_result():\n",
    "    # Evaluation\n",
    "    print \"Below are the accuracy, AUC, F1 score, precision, and recall: \"\n",
    "    print clf.score(X_test, y_test)\n",
    "    print roc_auc_score(y_test, y_pred)\n",
    "    print f1_score(y_test, y_pred)\n",
    "    print precision_score(y_test, y_pred)\n",
    "    print recall_score(y_test, y_pred)\n",
    "\n",
    "    print \"Confusion Matrix: \"\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print cm\n",
    "    #false positive\n",
    "    print 'false positive: ' + str(cm[0][1])\n",
    "    #false negative\n",
    "    print 'false negative: ' + str(cm[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data, target, test_size=0.2, random_state=0)\n",
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.814589546382\n",
      "0.754172050777\n",
      "0.871906091577\n",
      "0.836115010659\n",
      "0.910898379971\n",
      "Confusion Matrix: \n",
      "[[ 4678  3152]\n",
      " [ 1573 16081]]\n",
      "false positive: 3152\n",
      "false negative: 1573\n"
     ]
    }
   ],
   "source": [
    "eval_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [259 322 323 324 325 326 328 338 356 383 397 443 684] are constant.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "select = SelectKBest(f_classif, k = 600)\n",
    "data2 = select.fit_transform(data, target)\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data2, target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.814314864229\n",
      "0.753867191123\n",
      "0.871712844982\n",
      "0.835950499168\n",
      "0.910671802424\n",
      "Confusion Matrix: \n",
      "[[ 4675  3155]\n",
      " [ 1577 16077]]\n",
      "false positive: 3155\n",
      "false negative: 1577\n"
     ]
    }
   ],
   "source": [
    "eval_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select = SelectKBest(f_classif, k = 500)\n",
    "data2 = select.fit_transform(data, target)\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data2, target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.81329461623\n",
      "0.751069797604\n",
      "0.871321938555\n",
      "0.833712866163\n",
      "0.912484422794\n",
      "Confusion Matrix: \n",
      "[[ 4617  3213]\n",
      " [ 1545 16109]]\n",
      "false positive: 3213\n",
      "false negative: 1545\n"
     ]
    }
   ],
   "source": [
    "eval_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.813569298383\n",
      "0.752014283067\n",
      "0.871389513007\n",
      "0.834499922227\n",
      "0.911691401382\n",
      "Confusion Matrix: \n",
      "[[ 4638  3192]\n",
      " [ 1559 16095]]\n",
      "false positive: 3192\n",
      "false negative: 1559\n"
     ]
    }
   ],
   "source": [
    "select = SelectKBest(f_classif, k = 400)\n",
    "data2 = select.fit_transform(data, target)\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data2, target, test_size=0.2, random_state=0)\n",
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "eval_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.813098414692\n",
      "0.750928186637\n",
      "0.871169294853\n",
      "0.833669824507\n",
      "0.912201200861\n",
      "Confusion Matrix: \n",
      "[[ 4617  3213]\n",
      " [ 1550 16104]]\n",
      "false positive: 3213\n",
      "false negative: 1550\n"
     ]
    }
   ],
   "source": [
    "select = SelectKBest(f_classif, k = 300)\n",
    "data2 = select.fit_transform(data, target)\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data2, target, test_size=0.2, random_state=0)\n",
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "eval_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.814393344844\n",
      "0.753497418304\n",
      "0.87185739055\n",
      "0.83554886281\n",
      "0.911464823836\n",
      "Confusion Matrix: \n",
      "[[ 4663  3167]\n",
      " [ 1563 16091]]\n",
      "false positive: 3167\n",
      "false negative: 1563\n"
     ]
    }
   ],
   "source": [
    "select = SelectKBest(f_classif, k = 200)\n",
    "data2 = select.fit_transform(data, target)\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data2, target, test_size=0.2, random_state=0)\n",
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "eval_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.809252864542\n",
      "0.744990017422\n",
      "0.868802461472\n",
      "0.829767489818\n",
      "0.911691401382\n",
      "Confusion Matrix: \n",
      "[[ 4528  3302]\n",
      " [ 1559 16095]]\n",
      "false positive: 3302\n",
      "false negative: 1559\n"
     ]
    }
   ],
   "source": [
    "select = SelectKBest(f_classif, k = 100)\n",
    "data2 = select.fit_transform(data, target)\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data2, target, test_size=0.2, random_state=0)\n",
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "eval_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127418, 303)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:,range(1,304)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with only event feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.813373096845\n",
      "0.752334624073\n",
      "0.871146030886\n",
      "0.834908599917\n",
      "0.910671802424\n",
      "Confusion Matrix: \n",
      "[[ 4651  3179]\n",
      " [ 1577 16077]]\n",
      "false positive: 3179\n",
      "false negative: 1577\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data[:,range(1,304)], target, test_size=0.2, random_state=0)\n",
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "eval_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with only event + userbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the accuracy, AUC, F1 score, precision, and recall: \n",
      "0.81345157746\n",
      "0.752462337994\n",
      "0.871193237239\n",
      "0.834995325647\n",
      "0.910671802424\n",
      "Confusion Matrix: \n",
      "[[ 4653  3177]\n",
      " [ 1577 16077]]\n",
      "false positive: 3177\n",
      "false negative: 1577\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data[:, range(1,449)], target, test_size=0.2, random_state=0)\n",
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "eval_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with only event + expenditure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data[:, range(1,304) + range(449,486)], target, test_size=0.2, random_state=0)\n",
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "eval_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with only event + additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data[:, range(1,304) + range(486,710)], target, test_size=0.2, random_state=0)\n",
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "eval_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with only event + userbase + additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data[:, range(1,499)  + range(486,710)], target, test_size=0.2, random_state=0)\n",
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "eval_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with only event + expenditure + additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data[:, range(1,304) + range(449,486) + range(486,710)], target, test_size=0.2, random_state=0)\n",
    "clf = GradientBoostingClassifier(learning_rate = 0.15, loss='exponential', n_estimators = 300).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "eval_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
